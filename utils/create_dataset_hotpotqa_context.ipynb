{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hotpotqa \\nQn -> answer + context (CL < 600)'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Hotpotqa \n",
    "Qn -> answer + context (CL < 600)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/ganesh/vishak/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotpotqa_dataset = load_dataset('hotpot_qa', 'distractor')\n",
    "train_data = hotpotqa_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_traindata_alpaca_format = []\n",
    "for item in train_data:\n",
    "    titles = item['supporting_facts']['title']\n",
    "    context=''\n",
    "    for title in titles:\n",
    "        context_titles = item['context']['title']\n",
    "        index = context_titles.index(title)\n",
    "        context = context + ''.join(item['context']['sentences'][index])\n",
    "    \n",
    "    if (len(context) <= 600):\n",
    "        temp={}\n",
    "        instruction = instruction = \"Generate attributable background context from Wikipedia to answer the given question and answer the given question based on the generated context.\"\n",
    "        input_ = \"Question: \" + item['question']\n",
    "        output = \"###Answer: \" + item['answer'] + \" ###Context: \" + context + \" ###END\"\n",
    "        temp['instruction'] = instruction\n",
    "        temp['input'] = input_\n",
    "        temp['output'] = output\n",
    "        finetune_traindata_alpaca_format.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Generate attributable background context from Wikipedia to answer the given question and answer the given question based on the generated context.',\n",
       " 'input': \"Question: Which magazine was started first Arthur's Magazine or First for Women?\",\n",
       " 'output': '###Answer: Arthur\\'s Magazine ###Context: Arthur\\'s Magazine (1844–1846) was an American literary periodical published in Philadelphia in the 19th century. Edited by T.S. Arthur, it featured work by Edgar A. Poe, J.H. Ingraham, Sarah Josepha Hale, Thomas G. Spear, and others. In May 1846 it was merged into \"Godey\\'s Lady\\'s Book\".First for Women is a woman\\'s magazine published by Bauer Media Group in the USA. The magazine was started in 1989. It is based in Englewood Cliffs, New Jersey. In 2011 the circulation of the magazine was 1,310,696 copies. ###END'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_traindata_alpaca_format[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17881"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(finetune_traindata_alpaca_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 17881/17881 [00:00<00:00, 1269351.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "dataset = Dataset.from_pandas(pd.DataFrame(data=finetune_traindata_alpaca_format))\n",
    "dataset_dict = DatasetDict({\"train\": dataset})\n",
    "\n",
    "dataset_dict.save_to_disk(\"../lora-instruct/finetune_hotpotqa_traindata_input_qn_op_answer_context_CL600\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 22 2023, 10:22:35) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
